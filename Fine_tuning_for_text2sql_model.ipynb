{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7tfmppwXz7S"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLyd9_gsZDhj",
        "outputId": "49add9b9-383d-4336-d1c3-e57ad85749b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='t5-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "original_model = original_model"
      ],
      "metadata": {
        "id": "CAsTlj29YdWz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
        "dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
        "dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
        "\n",
        "dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]')\n",
        "dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text'])\n",
        "dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]')\n",
        "dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text'])\n",
        "dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]')\n",
        "dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
        "dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "\n",
        "dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
        "dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
        "dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
        "\n",
        "dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
        "                        'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
        "                        'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n"
      ],
      "metadata": {
        "id": "ecuTSaJwZf2R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGvhuB7oZtQy",
        "outputId": "0b24bcf6-3b52-4ca7-90f8-99a973e74f25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['answer', 'question', 'context'],\n",
              "        num_rows: 118695\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['answer', 'question', 'context'],\n",
              "        num_rows: 14835\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['answer', 'question', 'context'],\n",
              "        num_rows: 14838\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faPCPFDNZ7Jp",
        "outputId": "e4f24ce3-2686-4280-cc12-8cb398e7740f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'SELECT date FROM table_name_11 WHERE away_team = \"essendon\"',\n",
              " 'question': 'On what Date did the Away team essendon play?',\n",
              " 'context': 'CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    start_prompt = \"Tables:\\n\"\n",
        "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
        "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
        "\n",
        "    data_zip = zip(example['context'], example['question'])\n",
        "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "id": "t9vdlLmdZ_Fd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer'])"
      ],
      "metadata": {
        "id": "VFajl48ZaJzE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "finetuned_model = finetuned_model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "9Ua0aToXaRdh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3OOmiYfg7mV",
        "outputId": "d021b4d3-60d3-4aa5-db18-6a4a977706e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'labels'],\n",
              "    num_rows: 14835\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"/content/Result\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=5e-3,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=finetuned_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['test'],\n",
        "    # here test dataset is used because compute is note there so we are not using train dataset (tokenized_datasets['test'])\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "finetuned_model.save_pretrained(\"finetuned_model_1_epoch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "3HvE9962aiSl",
        "outputId": "be30f54b-24f7-4e11-df90-a1177b400d9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='928' max='928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [928/928 34:17, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>0.053022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "# index = len(dataset['test'])-200\n",
        "\n",
        "question = dataset['train'][index]['question']\n",
        "context = dataset['train'][index]['context']\n",
        "answer = dataset['train'][index]['answer']\n",
        "\n",
        "prompt = f\"\"\"Tables:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs = inputs.to('cuda')\n",
        "\n",
        "output = tokenizer.decode(\n",
        "    finetuned_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
        "print(dash_line)\n",
        "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkcueLDHep0f",
        "outputId": "6d4e0c9c-2c1c-4a47-b42d-f98f23cf4033"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "Tables:\n",
            "CREATE TABLE head (age INTEGER)\n",
            "\n",
            "Question:\n",
            "How many heads of the departments are older than 56 ?\n",
            "\n",
            "Answer:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN ANSWER:\n",
            "SELECT COUNT(*) FROM head WHERE age > 56\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "FINE-TUNED MODEL - ZERO SHOT:\n",
            "SELECT MIN(departure) FROM head_offering WHERE head_offering ON a.events.ite_id = '56' AND a.event_id = '56' AND a.e.events.itemid = '56' AND a.events.itemid = '56' AND a.year  '56'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VpGTDXfs2hL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}